{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BREAST CANCER PROJECT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119513</td>\n",
       "      <td>N</td>\n",
       "      <td>31</td>\n",
       "      <td>18.02</td>\n",
       "      <td>27.60</td>\n",
       "      <td>117.50</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.09489</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.10860</td>\n",
       "      <td>...</td>\n",
       "      <td>139.70</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>0.11950</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8423</td>\n",
       "      <td>N</td>\n",
       "      <td>61</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>842517</td>\n",
       "      <td>N</td>\n",
       "      <td>116</td>\n",
       "      <td>21.37</td>\n",
       "      <td>17.44</td>\n",
       "      <td>137.50</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>...</td>\n",
       "      <td>159.10</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>0.11880</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.20320</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.09067</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>843483</td>\n",
       "      <td>N</td>\n",
       "      <td>123</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843584</td>\n",
       "      <td>R</td>\n",
       "      <td>27</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>942640</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>22.52</td>\n",
       "      <td>21.92</td>\n",
       "      <td>146.90</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>0.07592</td>\n",
       "      <td>0.09162</td>\n",
       "      <td>0.06862</td>\n",
       "      <td>...</td>\n",
       "      <td>162.10</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>0.08191</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.09378</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.05788</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>943471</td>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>15.44</td>\n",
       "      <td>31.18</td>\n",
       "      <td>101.00</td>\n",
       "      <td>740.4</td>\n",
       "      <td>0.09399</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.13750</td>\n",
       "      <td>...</td>\n",
       "      <td>112.60</td>\n",
       "      <td>929.0</td>\n",
       "      <td>0.12720</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>0.12860</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.08024</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>94547</td>\n",
       "      <td>N</td>\n",
       "      <td>12</td>\n",
       "      <td>17.17</td>\n",
       "      <td>29.19</td>\n",
       "      <td>110.00</td>\n",
       "      <td>915.3</td>\n",
       "      <td>0.08952</td>\n",
       "      <td>0.06655</td>\n",
       "      <td>0.06583</td>\n",
       "      <td>...</td>\n",
       "      <td>132.50</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>0.12610</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>0.09520</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>0.06033</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>947204</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>21.42</td>\n",
       "      <td>22.84</td>\n",
       "      <td>145.00</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>0.10700</td>\n",
       "      <td>0.19390</td>\n",
       "      <td>0.23800</td>\n",
       "      <td>...</td>\n",
       "      <td>198.30</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>0.14980</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>0.5411</td>\n",
       "      <td>0.22150</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.08981</td>\n",
       "      <td>3.0</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>947489</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>16.70</td>\n",
       "      <td>28.13</td>\n",
       "      <td>110.30</td>\n",
       "      <td>885.4</td>\n",
       "      <td>0.08896</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.10120</td>\n",
       "      <td>...</td>\n",
       "      <td>128.80</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.2808</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.13170</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>0.08036</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1    2      3      4       5       6        7        8        9   \\\n",
       "0    119513  N   31  18.02  27.60  117.50  1013.0  0.09489  0.10360  0.10860   \n",
       "1      8423  N   61  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010   \n",
       "2    842517  N  116  21.37  17.44  137.50  1373.0  0.08836  0.11890  0.12550   \n",
       "3    843483  N  123  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
       "4    843584  R   27  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
       "..      ... ..  ...    ...    ...     ...     ...      ...      ...      ...   \n",
       "193  942640  N   10  22.52  21.92  146.90  1597.0  0.07592  0.09162  0.06862   \n",
       "194  943471  N    8  15.44  31.18  101.00   740.4  0.09399  0.10620  0.13750   \n",
       "195   94547  N   12  17.17  29.19  110.00   915.3  0.08952  0.06655  0.06583   \n",
       "196  947204  R    3  21.42  22.84  145.00  1440.0  0.10700  0.19390  0.23800   \n",
       "197  947489  N    6  16.70  28.13  110.30   885.4  0.08896  0.11310  0.10120   \n",
       "\n",
       "     ...      25      26       27      28      29       30      31       32  \\\n",
       "0    ...  139.70  1436.0  0.11950  0.1926  0.3140  0.11700  0.2677  0.08113   \n",
       "1    ...  184.60  2019.0  0.16220  0.6656  0.7119  0.26540  0.4601  0.11890   \n",
       "2    ...  159.10  1949.0  0.11880  0.3449  0.3414  0.20320  0.4334  0.09067   \n",
       "3    ...   98.87   567.7  0.20980  0.8663  0.6869  0.25750  0.6638  0.17300   \n",
       "4    ...  152.20  1575.0  0.13740  0.2050  0.4000  0.16250  0.2364  0.07678   \n",
       "..   ...     ...     ...      ...     ...     ...      ...     ...      ...   \n",
       "193  ...  162.10  1902.0  0.08191  0.1319  0.1056  0.09378  0.2061  0.05788   \n",
       "194  ...  112.60   929.0  0.12720  0.2362  0.2975  0.12860  0.2914  0.08024   \n",
       "195  ...  132.50  1295.0  0.12610  0.1572  0.2141  0.09520  0.3362  0.06033   \n",
       "196  ...  198.30  2375.0  0.14980  0.4379  0.5411  0.22150  0.2832  0.08981   \n",
       "197  ...  128.80  1213.0  0.13300  0.2808  0.3455  0.13170  0.3035  0.08036   \n",
       "\n",
       "      33  34  \n",
       "0    5.0   5  \n",
       "1    3.0   2  \n",
       "2    2.5   0  \n",
       "3    2.0   0  \n",
       "4    3.5   0  \n",
       "..   ...  ..  \n",
       "193  6.0   2  \n",
       "194  1.5   0  \n",
       "195  3.7   0  \n",
       "196  3.0   ?  \n",
       "197  3.5   0  \n",
       "\n",
       "[198 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('BCP2.csv',header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of          0  1    2      3      4       5       6        7        8        9   \\\n",
       "0    119513  N   31  18.02  27.60  117.50  1013.0  0.09489  0.10360  0.10860   \n",
       "1      8423  N   61  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010   \n",
       "2    842517  N  116  21.37  17.44  137.50  1373.0  0.08836  0.11890  0.12550   \n",
       "3    843483  N  123  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
       "4    843584  R   27  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
       "..      ... ..  ...    ...    ...     ...     ...      ...      ...      ...   \n",
       "193  942640  N   10  22.52  21.92  146.90  1597.0  0.07592  0.09162  0.06862   \n",
       "194  943471  N    8  15.44  31.18  101.00   740.4  0.09399  0.10620  0.13750   \n",
       "195   94547  N   12  17.17  29.19  110.00   915.3  0.08952  0.06655  0.06583   \n",
       "196  947204  R    3  21.42  22.84  145.00  1440.0  0.10700  0.19390  0.23800   \n",
       "197  947489  N    6  16.70  28.13  110.30   885.4  0.08896  0.11310  0.10120   \n",
       "\n",
       "     ...      25      26       27      28      29       30      31       32  \\\n",
       "0    ...  139.70  1436.0  0.11950  0.1926  0.3140  0.11700  0.2677  0.08113   \n",
       "1    ...  184.60  2019.0  0.16220  0.6656  0.7119  0.26540  0.4601  0.11890   \n",
       "2    ...  159.10  1949.0  0.11880  0.3449  0.3414  0.20320  0.4334  0.09067   \n",
       "3    ...   98.87   567.7  0.20980  0.8663  0.6869  0.25750  0.6638  0.17300   \n",
       "4    ...  152.20  1575.0  0.13740  0.2050  0.4000  0.16250  0.2364  0.07678   \n",
       "..   ...     ...     ...      ...     ...     ...      ...     ...      ...   \n",
       "193  ...  162.10  1902.0  0.08191  0.1319  0.1056  0.09378  0.2061  0.05788   \n",
       "194  ...  112.60   929.0  0.12720  0.2362  0.2975  0.12860  0.2914  0.08024   \n",
       "195  ...  132.50  1295.0  0.12610  0.1572  0.2141  0.09520  0.3362  0.06033   \n",
       "196  ...  198.30  2375.0  0.14980  0.4379  0.5411  0.22150  0.2832  0.08981   \n",
       "197  ...  128.80  1213.0  0.13300  0.2808  0.3455  0.13170  0.3035  0.08036   \n",
       "\n",
       "      33  34  \n",
       "0    5.0   5  \n",
       "1    3.0   2  \n",
       "2    2.5   0  \n",
       "3    2.0   0  \n",
       "4    3.5   0  \n",
       "..   ...  ..  \n",
       "193  6.0   2  \n",
       "194  1.5   0  \n",
       "195  3.7   0  \n",
       "196  3.0   ?  \n",
       "197  3.5   0  \n",
       "\n",
       "[198 rows x 35 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    151\n",
       "R     47\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1    2      3      4       5       6        7        8        9        10  \\\n",
      "0    N   31  18.02  27.60  117.50  1013.0  0.09489  0.10360  0.10860  0.07055   \n",
      "1    N   61  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710   \n",
      "2    N  116  21.37  17.44  137.50  1373.0  0.08836  0.11890  0.12550  0.08180   \n",
      "3    N  123  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520   \n",
      "4    R   27  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430   \n",
      "..  ..  ...    ...    ...     ...     ...      ...      ...      ...      ...   \n",
      "192  N    3  14.72  25.26   99.28   657.5  0.11740  0.21120  0.17290  0.09465   \n",
      "193  N   10  22.52  21.92  146.90  1597.0  0.07592  0.09162  0.06862  0.06367   \n",
      "194  N    8  15.44  31.18  101.00   740.4  0.09399  0.10620  0.13750  0.06500   \n",
      "195  N   12  17.17  29.19  110.00   915.3  0.08952  0.06655  0.06583  0.05068   \n",
      "197  N    6  16.70  28.13  110.30   885.4  0.08896  0.11310  0.10120  0.04989   \n",
      "\n",
      "     ...      25      26       27      28      29       30      31       32  \\\n",
      "0    ...  139.70  1436.0  0.11950  0.1926  0.3140  0.11700  0.2677  0.08113   \n",
      "1    ...  184.60  2019.0  0.16220  0.6656  0.7119  0.26540  0.4601  0.11890   \n",
      "2    ...  159.10  1949.0  0.11880  0.3449  0.3414  0.20320  0.4334  0.09067   \n",
      "3    ...   98.87   567.7  0.20980  0.8663  0.6869  0.25750  0.6638  0.17300   \n",
      "4    ...  152.20  1575.0  0.13740  0.2050  0.4000  0.16250  0.2364  0.07678   \n",
      "..   ...     ...     ...      ...     ...     ...      ...     ...      ...   \n",
      "192  ...  111.60   814.8  0.14640  0.5352  0.5655  0.19740  0.3778  0.11320   \n",
      "193  ...  162.10  1902.0  0.08191  0.1319  0.1056  0.09378  0.2061  0.05788   \n",
      "194  ...  112.60   929.0  0.12720  0.2362  0.2975  0.12860  0.2914  0.08024   \n",
      "195  ...  132.50  1295.0  0.12610  0.1572  0.2141  0.09520  0.3362  0.06033   \n",
      "197  ...  128.80  1213.0  0.13300  0.2808  0.3455  0.13170  0.3035  0.08036   \n",
      "\n",
      "      33  34  \n",
      "0    5.0   5  \n",
      "1    3.0   2  \n",
      "2    2.5   0  \n",
      "3    2.0   0  \n",
      "4    3.5   0  \n",
      "..   ...  ..  \n",
      "192  1.7  21  \n",
      "193  6.0   2  \n",
      "194  1.5   0  \n",
      "195  3.7   0  \n",
      "197  3.5   0  \n",
      "\n",
      "[194 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(0,axis=1)\n",
    "df = df.drop(196)\n",
    "df = df.drop(85)\n",
    "df = df.drop(28)\n",
    "df = df.drop(6)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of     1    2      3      4       5       6        7        8        9        10  \\\n",
       "0    N   31  18.02  27.60  117.50  1013.0  0.09489  0.10360  0.10860  0.07055   \n",
       "1    N   61  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710   \n",
       "2    N  116  21.37  17.44  137.50  1373.0  0.08836  0.11890  0.12550  0.08180   \n",
       "3    N  123  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520   \n",
       "4    R   27  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430   \n",
       "..  ..  ...    ...    ...     ...     ...      ...      ...      ...      ...   \n",
       "192  N    3  14.72  25.26   99.28   657.5  0.11740  0.21120  0.17290  0.09465   \n",
       "193  N   10  22.52  21.92  146.90  1597.0  0.07592  0.09162  0.06862  0.06367   \n",
       "194  N    8  15.44  31.18  101.00   740.4  0.09399  0.10620  0.13750  0.06500   \n",
       "195  N   12  17.17  29.19  110.00   915.3  0.08952  0.06655  0.06583  0.05068   \n",
       "197  N    6  16.70  28.13  110.30   885.4  0.08896  0.11310  0.10120  0.04989   \n",
       "\n",
       "     ...      25      26       27      28      29       30      31       32  \\\n",
       "0    ...  139.70  1436.0  0.11950  0.1926  0.3140  0.11700  0.2677  0.08113   \n",
       "1    ...  184.60  2019.0  0.16220  0.6656  0.7119  0.26540  0.4601  0.11890   \n",
       "2    ...  159.10  1949.0  0.11880  0.3449  0.3414  0.20320  0.4334  0.09067   \n",
       "3    ...   98.87   567.7  0.20980  0.8663  0.6869  0.25750  0.6638  0.17300   \n",
       "4    ...  152.20  1575.0  0.13740  0.2050  0.4000  0.16250  0.2364  0.07678   \n",
       "..   ...     ...     ...      ...     ...     ...      ...     ...      ...   \n",
       "192  ...  111.60   814.8  0.14640  0.5352  0.5655  0.19740  0.3778  0.11320   \n",
       "193  ...  162.10  1902.0  0.08191  0.1319  0.1056  0.09378  0.2061  0.05788   \n",
       "194  ...  112.60   929.0  0.12720  0.2362  0.2975  0.12860  0.2914  0.08024   \n",
       "195  ...  132.50  1295.0  0.12610  0.1572  0.2141  0.09520  0.3362  0.06033   \n",
       "197  ...  128.80  1213.0  0.13300  0.2808  0.3455  0.13170  0.3035  0.08036   \n",
       "\n",
       "      33  34  \n",
       "0    5.0   5  \n",
       "1    3.0   2  \n",
       "2    2.5   0  \n",
       "3    2.0   0  \n",
       "4    3.5   0  \n",
       "..   ...  ..  \n",
       "192  1.7  21  \n",
       "193  6.0   2  \n",
       "194  1.5   0  \n",
       "195  3.7   0  \n",
       "197  3.5   0  \n",
       "\n",
       "[194 rows x 34 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    148\n",
       "1     46\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {'N':0,'R':1}\n",
    "df1 = df\n",
    "df1[1]=df[1].map(dict)\n",
    "df[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1.iloc[:,:1]\n",
    "x = df1.iloc[:,1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 33)\n",
      "(116, 33)\n",
      "(78, 33)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.4,random_state=0)\n",
    "print(x.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.25\n",
      "Testing Acc= 0.28205128205128205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.8275862068965517\n",
      "Testing Acc= 0.782051282051282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.7844827586206896\n",
      "Testing Acc= 0.7307692307692307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf=SVC()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.7931034482758621\n",
      "Testing Acc= 0.7051282051282052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-57105c2c3f92>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(x_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf=KNeighborsClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.7672413793103449\n",
      "Testing Acc= 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf= GaussianNB()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 1.0\n",
      "Testing Acc= 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf= DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-8ba343966504>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(x_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 1.0\n",
      "Testing Acc= 0.7051282051282052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf= RandomForestClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.9827586206896551\n",
      "Testing Acc= 0.7307692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf= BaggingClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-fe3a7a521dac>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(x_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 1.0\n",
      "Testing Acc= 0.7051282051282052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf= ExtraTreesClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 1.0\n",
      "Testing Acc= 0.7307692307692307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "clf= AdaBoostClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-20-5bcc79759992>:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  model.fit(x_train,y_train)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-20-5bcc79759992>:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x_train,y_train)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-20-5bcc79759992>:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x_train,y_train)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Per': 0.28205128205128205, 'LR': 0.782051282051282, 'SVC': 0.7307692307692307, 'KNN': 0.7051282051282052, 'GNB': 0.6666666666666666, 'DT': 0.6538461538461539, 'RT': 0.7307692307692307, 'BAG': 0.7564102564102564, 'ET': 0.7564102564102564, 'ADA': 0.7307692307692307, 'GBC': 0.7692307692307693, 'VT': 0.6410256410256411}\n",
      "Per : 0.28205128205128205\n",
      "LR : 0.782051282051282\n",
      "SVC : 0.7307692307692307\n",
      "KNN : 0.7051282051282052\n",
      "GNB : 0.6666666666666666\n",
      "DT : 0.6538461538461539\n",
      "RT : 0.7307692307692307\n",
      "BAG : 0.7564102564102564\n",
      "ET : 0.7564102564102564\n",
      "ADA : 0.7307692307692307\n",
      "GBC : 0.7692307692307693\n",
      "VT : 0.6410256410256411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier,AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,VotingClassifier\n",
    "clf1 = Perceptron()\n",
    "clf2 =LogisticRegression()\n",
    "clf3 = SVC()\n",
    "clf4= KNeighborsClassifier()\n",
    "clf5 = GaussianNB()\n",
    "clf6= DecisionTreeClassifier()\n",
    "clf7= RandomForestClassifier()\n",
    "clf8= BaggingClassifier()\n",
    "clf9= ExtraTreesClassifier()\n",
    "clf10= AdaBoostClassifier()\n",
    "clf11= GradientBoostingClassifier()\n",
    "clf12 = VotingClassifier(estimators=[('per',clf1),('dt',clf6),('ada',clf10),],voting='hard')\n",
    "clf=[clf1,clf2,clf3,clf4,clf5,clf6,clf7,clf8,clf9,clf10,clf11,clf12]\n",
    "name=['Per','LR','SVC','KNN','GNB','DT','RT','BAG','ET','ADA','GBC','VT']\n",
    "accuracy={}\n",
    "for model,model_name in zip(clf,name):\n",
    "    model.fit(x_train,y_train)\n",
    "    acc = accuracy_score(model.predict(x_test),y_test)\n",
    "    accuracy[model_name]=acc\n",
    "print(accuracy)\n",
    "for i,j in accuracy.items():\n",
    "    print(i,':',j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classifiers = []\n",
    "ac= []\n",
    "for i,j in accuracy.items():\n",
    "    classifiers.append(i)\n",
    "    ac.append(j)\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "plt.bar(classifiers,ac,color=\"Black\")\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  7]\n",
      " [14  7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_test_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm,annot=True,cbar=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 100.0\n",
      "Testing Acc= 73.07692307692307\n",
      "Cross Validation 0.7307692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-5ab407ebbcfd>:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "model=RandomForestClassifier(n_estimators=25,min_samples_split=50,max_depth=7,max_features=1)\n",
    "model.fit(x_train,y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc*100)\n",
    "print('Testing Acc=',test_acc*100)\n",
    "print(\"Cross Validation\",model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
