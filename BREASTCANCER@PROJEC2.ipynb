{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BREAST CANCER PROJECT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119513</td>\n",
       "      <td>N</td>\n",
       "      <td>31</td>\n",
       "      <td>18.02</td>\n",
       "      <td>27.60</td>\n",
       "      <td>117.50</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>0.09489</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.10860</td>\n",
       "      <td>...</td>\n",
       "      <td>139.70</td>\n",
       "      <td>1436.0</td>\n",
       "      <td>0.11950</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8423</td>\n",
       "      <td>N</td>\n",
       "      <td>61</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>842517</td>\n",
       "      <td>N</td>\n",
       "      <td>116</td>\n",
       "      <td>21.37</td>\n",
       "      <td>17.44</td>\n",
       "      <td>137.50</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>...</td>\n",
       "      <td>159.10</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>0.11880</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>0.20320</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.09067</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>843483</td>\n",
       "      <td>N</td>\n",
       "      <td>123</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>843584</td>\n",
       "      <td>R</td>\n",
       "      <td>27</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>942640</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>22.52</td>\n",
       "      <td>21.92</td>\n",
       "      <td>146.90</td>\n",
       "      <td>1597.0</td>\n",
       "      <td>0.07592</td>\n",
       "      <td>0.09162</td>\n",
       "      <td>0.06862</td>\n",
       "      <td>...</td>\n",
       "      <td>162.10</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>0.08191</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.09378</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.05788</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>943471</td>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>15.44</td>\n",
       "      <td>31.18</td>\n",
       "      <td>101.00</td>\n",
       "      <td>740.4</td>\n",
       "      <td>0.09399</td>\n",
       "      <td>0.10620</td>\n",
       "      <td>0.13750</td>\n",
       "      <td>...</td>\n",
       "      <td>112.60</td>\n",
       "      <td>929.0</td>\n",
       "      <td>0.12720</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>0.12860</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.08024</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>94547</td>\n",
       "      <td>N</td>\n",
       "      <td>12</td>\n",
       "      <td>17.17</td>\n",
       "      <td>29.19</td>\n",
       "      <td>110.00</td>\n",
       "      <td>915.3</td>\n",
       "      <td>0.08952</td>\n",
       "      <td>0.06655</td>\n",
       "      <td>0.06583</td>\n",
       "      <td>...</td>\n",
       "      <td>132.50</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>0.12610</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>0.09520</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>0.06033</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>947204</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>21.42</td>\n",
       "      <td>22.84</td>\n",
       "      <td>145.00</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>0.10700</td>\n",
       "      <td>0.19390</td>\n",
       "      <td>0.23800</td>\n",
       "      <td>...</td>\n",
       "      <td>198.30</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>0.14980</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>0.5411</td>\n",
       "      <td>0.22150</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.08981</td>\n",
       "      <td>3.0</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>947489</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>16.70</td>\n",
       "      <td>28.13</td>\n",
       "      <td>110.30</td>\n",
       "      <td>885.4</td>\n",
       "      <td>0.08896</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.10120</td>\n",
       "      <td>...</td>\n",
       "      <td>128.80</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>0.13300</td>\n",
       "      <td>0.2808</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.13170</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>0.08036</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1    2      3      4       5       6        7        8        9   \\\n",
       "0    119513  N   31  18.02  27.60  117.50  1013.0  0.09489  0.10360  0.10860   \n",
       "1      8423  N   61  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010   \n",
       "2    842517  N  116  21.37  17.44  137.50  1373.0  0.08836  0.11890  0.12550   \n",
       "3    843483  N  123  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
       "4    843584  R   27  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
       "..      ... ..  ...    ...    ...     ...     ...      ...      ...      ...   \n",
       "193  942640  N   10  22.52  21.92  146.90  1597.0  0.07592  0.09162  0.06862   \n",
       "194  943471  N    8  15.44  31.18  101.00   740.4  0.09399  0.10620  0.13750   \n",
       "195   94547  N   12  17.17  29.19  110.00   915.3  0.08952  0.06655  0.06583   \n",
       "196  947204  R    3  21.42  22.84  145.00  1440.0  0.10700  0.19390  0.23800   \n",
       "197  947489  N    6  16.70  28.13  110.30   885.4  0.08896  0.11310  0.10120   \n",
       "\n",
       "     ...      25      26       27      28      29       30      31       32  \\\n",
       "0    ...  139.70  1436.0  0.11950  0.1926  0.3140  0.11700  0.2677  0.08113   \n",
       "1    ...  184.60  2019.0  0.16220  0.6656  0.7119  0.26540  0.4601  0.11890   \n",
       "2    ...  159.10  1949.0  0.11880  0.3449  0.3414  0.20320  0.4334  0.09067   \n",
       "3    ...   98.87   567.7  0.20980  0.8663  0.6869  0.25750  0.6638  0.17300   \n",
       "4    ...  152.20  1575.0  0.13740  0.2050  0.4000  0.16250  0.2364  0.07678   \n",
       "..   ...     ...     ...      ...     ...     ...      ...     ...      ...   \n",
       "193  ...  162.10  1902.0  0.08191  0.1319  0.1056  0.09378  0.2061  0.05788   \n",
       "194  ...  112.60   929.0  0.12720  0.2362  0.2975  0.12860  0.2914  0.08024   \n",
       "195  ...  132.50  1295.0  0.12610  0.1572  0.2141  0.09520  0.3362  0.06033   \n",
       "196  ...  198.30  2375.0  0.14980  0.4379  0.5411  0.22150  0.2832  0.08981   \n",
       "197  ...  128.80  1213.0  0.13300  0.2808  0.3455  0.13170  0.3035  0.08036   \n",
       "\n",
       "      33  34  \n",
       "0    5.0   5  \n",
       "1    3.0   2  \n",
       "2    2.5   0  \n",
       "3    2.0   0  \n",
       "4    3.5   0  \n",
       "..   ...  ..  \n",
       "193  6.0   2  \n",
       "194  1.5   0  \n",
       "195  3.7   0  \n",
       "196  3.0   ?  \n",
       "197  3.5   0  \n",
       "\n",
       "[198 rows x 35 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('BCP2.csv',header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of          0  1    2      3      4       5       6        7        8        9   \\\n",
       "0    119513  N   31  18.02  27.60  117.50  1013.0  0.09489  0.10360  0.10860   \n",
       "1      8423  N   61  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010   \n",
       "2    842517  N  116  21.37  17.44  137.50  1373.0  0.08836  0.11890  0.12550   \n",
       "3    843483  N  123  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
       "4    843584  R   27  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
       "..      ... ..  ...    ...    ...     ...     ...      ...      ...      ...   \n",
       "193  942640  N   10  22.52  21.92  146.90  1597.0  0.07592  0.09162  0.06862   \n",
       "194  943471  N    8  15.44  31.18  101.00   740.4  0.09399  0.10620  0.13750   \n",
       "195   94547  N   12  17.17  29.19  110.00   915.3  0.08952  0.06655  0.06583   \n",
       "196  947204  R    3  21.42  22.84  145.00  1440.0  0.10700  0.19390  0.23800   \n",
       "197  947489  N    6  16.70  28.13  110.30   885.4  0.08896  0.11310  0.10120   \n",
       "\n",
       "     ...      25      26       27      28      29       30      31       32  \\\n",
       "0    ...  139.70  1436.0  0.11950  0.1926  0.3140  0.11700  0.2677  0.08113   \n",
       "1    ...  184.60  2019.0  0.16220  0.6656  0.7119  0.26540  0.4601  0.11890   \n",
       "2    ...  159.10  1949.0  0.11880  0.3449  0.3414  0.20320  0.4334  0.09067   \n",
       "3    ...   98.87   567.7  0.20980  0.8663  0.6869  0.25750  0.6638  0.17300   \n",
       "4    ...  152.20  1575.0  0.13740  0.2050  0.4000  0.16250  0.2364  0.07678   \n",
       "..   ...     ...     ...      ...     ...     ...      ...     ...      ...   \n",
       "193  ...  162.10  1902.0  0.08191  0.1319  0.1056  0.09378  0.2061  0.05788   \n",
       "194  ...  112.60   929.0  0.12720  0.2362  0.2975  0.12860  0.2914  0.08024   \n",
       "195  ...  132.50  1295.0  0.12610  0.1572  0.2141  0.09520  0.3362  0.06033   \n",
       "196  ...  198.30  2375.0  0.14980  0.4379  0.5411  0.22150  0.2832  0.08981   \n",
       "197  ...  128.80  1213.0  0.13300  0.2808  0.3455  0.13170  0.3035  0.08036   \n",
       "\n",
       "      33  34  \n",
       "0    5.0   5  \n",
       "1    3.0   2  \n",
       "2    2.5   0  \n",
       "3    2.0   0  \n",
       "4    3.5   0  \n",
       "..   ...  ..  \n",
       "193  6.0   2  \n",
       "194  1.5   0  \n",
       "195  3.7   0  \n",
       "196  3.0   ?  \n",
       "197  3.5   0  \n",
       "\n",
       "[198 rows x 35 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    151\n",
       "R     47\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1    2      3      4       5       6        7        8        9        10  \\\n",
      "0    N   31  18.02  27.60  117.50  1013.0  0.09489  0.10360  0.10860  0.07055   \n",
      "1    N   61  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710   \n",
      "2    N  116  21.37  17.44  137.50  1373.0  0.08836  0.11890  0.12550  0.08180   \n",
      "3    N  123  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520   \n",
      "4    R   27  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430   \n",
      "..  ..  ...    ...    ...     ...     ...      ...      ...      ...      ...   \n",
      "192  N    3  14.72  25.26   99.28   657.5  0.11740  0.21120  0.17290  0.09465   \n",
      "193  N   10  22.52  21.92  146.90  1597.0  0.07592  0.09162  0.06862  0.06367   \n",
      "194  N    8  15.44  31.18  101.00   740.4  0.09399  0.10620  0.13750  0.06500   \n",
      "195  N   12  17.17  29.19  110.00   915.3  0.08952  0.06655  0.06583  0.05068   \n",
      "197  N    6  16.70  28.13  110.30   885.4  0.08896  0.11310  0.10120  0.04989   \n",
      "\n",
      "     ...      25      26       27      28      29       30      31       32  \\\n",
      "0    ...  139.70  1436.0  0.11950  0.1926  0.3140  0.11700  0.2677  0.08113   \n",
      "1    ...  184.60  2019.0  0.16220  0.6656  0.7119  0.26540  0.4601  0.11890   \n",
      "2    ...  159.10  1949.0  0.11880  0.3449  0.3414  0.20320  0.4334  0.09067   \n",
      "3    ...   98.87   567.7  0.20980  0.8663  0.6869  0.25750  0.6638  0.17300   \n",
      "4    ...  152.20  1575.0  0.13740  0.2050  0.4000  0.16250  0.2364  0.07678   \n",
      "..   ...     ...     ...      ...     ...     ...      ...     ...      ...   \n",
      "192  ...  111.60   814.8  0.14640  0.5352  0.5655  0.19740  0.3778  0.11320   \n",
      "193  ...  162.10  1902.0  0.08191  0.1319  0.1056  0.09378  0.2061  0.05788   \n",
      "194  ...  112.60   929.0  0.12720  0.2362  0.2975  0.12860  0.2914  0.08024   \n",
      "195  ...  132.50  1295.0  0.12610  0.1572  0.2141  0.09520  0.3362  0.06033   \n",
      "197  ...  128.80  1213.0  0.13300  0.2808  0.3455  0.13170  0.3035  0.08036   \n",
      "\n",
      "      33  34  \n",
      "0    5.0   5  \n",
      "1    3.0   2  \n",
      "2    2.5   0  \n",
      "3    2.0   0  \n",
      "4    3.5   0  \n",
      "..   ...  ..  \n",
      "192  1.7  21  \n",
      "193  6.0   2  \n",
      "194  1.5   0  \n",
      "195  3.7   0  \n",
      "197  3.5   0  \n",
      "\n",
      "[194 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(0,axis=1)\n",
    "df = df.drop(196)\n",
    "df = df.drop(85)\n",
    "df = df.drop(28)\n",
    "df = df.drop(6)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of     1    2      3      4       5       6        7        8        9        10  \\\n",
       "0    N   31  18.02  27.60  117.50  1013.0  0.09489  0.10360  0.10860  0.07055   \n",
       "1    N   61  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710   \n",
       "2    N  116  21.37  17.44  137.50  1373.0  0.08836  0.11890  0.12550  0.08180   \n",
       "3    N  123  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520   \n",
       "4    R   27  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430   \n",
       "..  ..  ...    ...    ...     ...     ...      ...      ...      ...      ...   \n",
       "192  N    3  14.72  25.26   99.28   657.5  0.11740  0.21120  0.17290  0.09465   \n",
       "193  N   10  22.52  21.92  146.90  1597.0  0.07592  0.09162  0.06862  0.06367   \n",
       "194  N    8  15.44  31.18  101.00   740.4  0.09399  0.10620  0.13750  0.06500   \n",
       "195  N   12  17.17  29.19  110.00   915.3  0.08952  0.06655  0.06583  0.05068   \n",
       "197  N    6  16.70  28.13  110.30   885.4  0.08896  0.11310  0.10120  0.04989   \n",
       "\n",
       "     ...      25      26       27      28      29       30      31       32  \\\n",
       "0    ...  139.70  1436.0  0.11950  0.1926  0.3140  0.11700  0.2677  0.08113   \n",
       "1    ...  184.60  2019.0  0.16220  0.6656  0.7119  0.26540  0.4601  0.11890   \n",
       "2    ...  159.10  1949.0  0.11880  0.3449  0.3414  0.20320  0.4334  0.09067   \n",
       "3    ...   98.87   567.7  0.20980  0.8663  0.6869  0.25750  0.6638  0.17300   \n",
       "4    ...  152.20  1575.0  0.13740  0.2050  0.4000  0.16250  0.2364  0.07678   \n",
       "..   ...     ...     ...      ...     ...     ...      ...     ...      ...   \n",
       "192  ...  111.60   814.8  0.14640  0.5352  0.5655  0.19740  0.3778  0.11320   \n",
       "193  ...  162.10  1902.0  0.08191  0.1319  0.1056  0.09378  0.2061  0.05788   \n",
       "194  ...  112.60   929.0  0.12720  0.2362  0.2975  0.12860  0.2914  0.08024   \n",
       "195  ...  132.50  1295.0  0.12610  0.1572  0.2141  0.09520  0.3362  0.06033   \n",
       "197  ...  128.80  1213.0  0.13300  0.2808  0.3455  0.13170  0.3035  0.08036   \n",
       "\n",
       "      33  34  \n",
       "0    5.0   5  \n",
       "1    3.0   2  \n",
       "2    2.5   0  \n",
       "3    2.0   0  \n",
       "4    3.5   0  \n",
       "..   ...  ..  \n",
       "192  1.7  21  \n",
       "193  6.0   2  \n",
       "194  1.5   0  \n",
       "195  3.7   0  \n",
       "197  3.5   0  \n",
       "\n",
       "[194 rows x 34 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    148\n",
       "1     46\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {'N':0,'R':1}\n",
    "df1 = df\n",
    "df1[1]=df[1].map(dict)\n",
    "df[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "..  ..\n",
      "192  0\n",
      "193  0\n",
      "194  0\n",
      "195  0\n",
      "197  0\n",
      "\n",
      "[194 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "y = df1.iloc[:,:1]\n",
    "x = df1.iloc[:,1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 33)\n",
      "(116, 33)\n",
      "(78, 33)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.4,random_state=0)\n",
    "print(x.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.25\n",
      "Testing Acc= 0.28205128205128205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.8275862068965517\n",
      "Testing Acc= 0.782051282051282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.7844827586206896\n",
      "Testing Acc= 0.7307692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf=SVC()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.7931034482758621\n",
      "Testing Acc= 0.7051282051282052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-57105c2c3f92>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  clf.fit(x_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf=KNeighborsClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.7672413793103449\n",
      "Testing Acc= 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf= GaussianNB()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 1.0\n",
      "Testing Acc= 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf= DecisionTreeClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-8ba343966504>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(x_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 1.0\n",
      "Testing Acc= 0.7564102564102564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf= RandomForestClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 0.9913793103448276\n",
      "Testing Acc= 0.7564102564102564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf= BaggingClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 1.0\n",
      "Testing Acc= 0.7307692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-fe3a7a521dac>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(x_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf= ExtraTreesClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc= 1.0\n",
      "Testing Acc= 0.7307692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "clf= AdaBoostClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "y_train_pred=clf.predict(x_train)\n",
    "y_test_pred=clf.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_acc=accuracy_score(y_train,y_train_pred)\n",
    "test_acc=accuracy_score(y_test,y_test_pred)\n",
    "print('Training Acc=',train_acc)\n",
    "print('Testing Acc=',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-34-5bcc79759992>:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  model.fit(x_train,y_train)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-34-5bcc79759992>:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x_train,y_train)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-34-5bcc79759992>:25: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(x_train,y_train)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Per': 0.28205128205128205, 'LR': 0.782051282051282, 'SVC': 0.7307692307692307, 'KNN': 0.7051282051282052, 'GNB': 0.6666666666666666, 'DT': 0.6282051282051282, 'RT': 0.717948717948718, 'BAG': 0.7051282051282052, 'ET': 0.7307692307692307, 'ADA': 0.7307692307692307, 'GBC': 0.7564102564102564, 'VT': 0.6538461538461539}\n",
      "Per : 0.28205128205128205\n",
      "LR : 0.782051282051282\n",
      "SVC : 0.7307692307692307\n",
      "KNN : 0.7051282051282052\n",
      "GNB : 0.6666666666666666\n",
      "DT : 0.6282051282051282\n",
      "RT : 0.717948717948718\n",
      "BAG : 0.7051282051282052\n",
      "ET : 0.7307692307692307\n",
      "ADA : 0.7307692307692307\n",
      "GBC : 0.7564102564102564\n",
      "VT : 0.6538461538461539\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier,AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,VotingClassifier\n",
    "clf1 = Perceptron()\n",
    "clf2 =LogisticRegression()\n",
    "clf3 = SVC()\n",
    "clf4= KNeighborsClassifier()\n",
    "clf5 = GaussianNB()\n",
    "clf6= DecisionTreeClassifier()\n",
    "clf7= RandomForestClassifier()\n",
    "clf8= BaggingClassifier()\n",
    "clf9= ExtraTreesClassifier()\n",
    "clf10= AdaBoostClassifier()\n",
    "clf11= GradientBoostingClassifier()\n",
    "clf12 = VotingClassifier(estimators=[('per',clf1),('dt',clf6),('ada',clf10),],voting='hard')\n",
    "clf=[clf1,clf2,clf3,clf4,clf5,clf6,clf7,clf8,clf9,clf10,clf11,clf12]\n",
    "name=['Per','LR','SVC','KNN','GNB','DT','RT','BAG','ET','ADA','GBC','VT']\n",
    "accuracy={}\n",
    "for model,model_name in zip(clf,name):\n",
    "    model.fit(x_train,y_train)\n",
    "    acc = accuracy_score(model.predict(x_test),y_test)\n",
    "    accuracy[model_name]=acc\n",
    "print(accuracy)\n",
    "for i,j in accuracy.items():\n",
    "    print(i,':',j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classifiers = []\n",
    "ac= []\n",
    "for i,j in accuracy.items():\n",
    "    classifiers.append(i)\n",
    "    ac.append(j)\n",
    "fig=plt.figure(figsize=(10,5))\n",
    "plt.bar(classifiers,ac,color=\"Black\")\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56  1]\n",
      " [16  5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_test_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm,annot=True,cbar=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
